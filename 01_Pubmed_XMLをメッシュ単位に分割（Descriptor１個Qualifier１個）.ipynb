{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "import defusedxml.ElementTree as ET\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import collections\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path_1 = '../Pubmed_original'\n",
    "path_2 = '../folder_01'\n",
    "os.chdir(path_1)\n",
    "print(os.getcwd())\n",
    "os.chdir(path_2)\n",
    "print(os.getcwd())\n",
    "os.chdir(path_1)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#現在のディレクトリの下の階層に「Pubmed_original」フォルダを配置する\n",
    "#あらかじめダウンロードしておいたPubmed文献データ(xml.gz)を格納しておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_0 = \"./Pubmed_original\"\n",
    "path_1 = \"../Pubmed_original\"\n",
    "path_2 = '../folder_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/admin_user/Pubmed_original\n",
      "1062\n"
     ]
    }
   ],
   "source": [
    "#あらかじめダウンロードしておいたPubmed文献データ（xml.gz)をリスト化\n",
    "os.chdir(path_0)\n",
    "print(os.getcwd())\n",
    "xml_list = sorted(glob.glob('*.xml.gz'))\n",
    "print(len(xml_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#要素を取り出す\n",
    "def getTextFromNode(root, path, fill='', mode=0, attrib='attribute'):\n",
    "    if (root.find(path) == None):\n",
    "        return fill\n",
    "    else:\n",
    "        if mode == 0:\n",
    "            return root.find(path).text\n",
    "        if mode == 1:\n",
    "            return root.find(path).get(attrib)\n",
    "#区切る\n",
    "SEP = '|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Qualifier\n",
    "\n",
    "#Name抽出\n",
    "def getTextFromNode_quali(root, path, fill='', mode=0, attrib='attribute'):\n",
    "    name_list = []\n",
    "    if (root.find(path) == None):\n",
    "        return fill\n",
    "    else:\n",
    "        \n",
    "        if mode == 0:\n",
    "            for i in root.findall('QualifierName'):                \n",
    "                name_list.append(i.text)\n",
    "            return '@@@'.join(name_list)\n",
    "        if mode == 1:           \n",
    "            return root.find(path).get(attrib)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Qualifier\n",
    "\n",
    "#UI抽出\n",
    "def getTextFromNode_quali_UI(root, path, fill='', mode=0, attrib='attribute'):\n",
    "    name_list = []\n",
    "    if (root.find(path) == None):\n",
    "        return fill\n",
    "    else:\n",
    "        \n",
    "        if mode == 1:\n",
    "            for i in root.findall('QualifierName'):                \n",
    "                name_list.append(i.get('UI'))\n",
    "            return '@@@'.join(name_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Qualifier\n",
    "\n",
    "#MajorTopicYN抽出\n",
    "def getTextFromNode_quali_YN(root, path, fill='', mode=0, attrib='attribute'):\n",
    "    name_list = []\n",
    "    if (root.find(path) == None):\n",
    "        return fill\n",
    "    else:\n",
    "        \n",
    "        if mode == 1:\n",
    "            for i in root.findall('QualifierName'):                \n",
    "                name_list.append(i.get('MajorTopicYN'))\n",
    "            return '@@@'.join(name_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#１個のDescriptorにQualifierが複数ついている ついていないこともある\n",
    "#Descriptor：Qualifier＝１：１に分割してそれぞれターム名・ID・MajorTopicを取り出す\n",
    "#PMIDもつける\n",
    "\n",
    "def one_descriptor_one_qualifier():\n",
    "    \n",
    "    pmid_one_desc_one_qual = []\n",
    "    for num, (pmid, pubdate) in enumerate(zip(df[\"PMID\"], df[\"PubMedPubDate\"])):\n",
    "        for desc_name, desc_ui, desc_mj, qual_names, qual_uis, qual_mjs in  zip( df[\"Descriptor\"][num], \n",
    "                                                                                df[\"Descriptor_UI\"][num],\n",
    "                                                                                df[\"Descriptor_MajorTopic\"][num],\n",
    "                                                                                df[\"Qualifier\"][num],\n",
    "                                                                                df[\"Qualifier_UI\"][num],\n",
    "                                                                                df[\"Qualifier_MajorTopic\"][num],\n",
    "                                                                               ):\n",
    "            for qual_name, qual_ui, qual_mj in zip(qual_names.split('@@@'), qual_uis.split('@@@'), qual_mjs.split('@@@') ):\n",
    "                pmid_one_desc_one_qual.append([pmid, pubdate, desc_name, desc_ui, desc_mj, qual_name, qual_ui, qual_mj])\n",
    "    \n",
    "    tmp_df = pd.DataFrame(pmid_one_desc_one_qual, \n",
    "                          columns=[\"PMID\", \"PubDate\",\"Descriptor\", \"Descriptor_UI\", \"Descriptor_MajorTopic\", \n",
    "                                                      \"Qualifier\", \"Qualifier_UI\",\"Qualifier_MajorTopic\"])\n",
    "    \n",
    "    #to csv\n",
    "    csv_name =  \"one_desc_one_qual_\" + file[9:-6]+\"csv\"\n",
    "    tmp_df.to_csv(csv_name, index=False)\n",
    "    #print(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe859209b9b400bb6f9383d8a4644e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for num, file in tqdm(enumerate(xml_list[:])):\n",
    "    #print(file)\n",
    "    \n",
    "    input = gzip.open(file, 'r')\n",
    "    tree = ET.parse(input)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    articleDics=[]\n",
    "    for article in tree.iter('PubmedArticle'):\n",
    "        articleDic = {\n",
    "            'PMID'                    : getTextFromNode(article, 'MedlineCitation/PMID', ''),\n",
    "            'PubMedPubDate_Y'         : getTextFromNode(article, 'PubmedData/History/PubMedPubDate[@PubStatus=\"pubmed\"]/Year', ''),\n",
    "            'PubMedPubDate_M'         : getTextFromNode(article, 'PubmedData/History/PubMedPubDate[@PubStatus=\"pubmed\"]/Month', ''),\n",
    "            'PubMedPubDate_D'         : getTextFromNode(article, 'PubmedData/History/PubMedPubDate[@PubStatus=\"pubmed\"]/Day', ''),\n",
    "            'Descriptor'              : SEP.join([getTextFromNode(mesh, 'DescriptorName') for mesh in article.findall('MedlineCitation/MeshHeadingList/')]),\n",
    "            'Descriptor_UI'           : SEP.join([getTextFromNode(mesh, 'DescriptorName', '', 1, 'UI') for mesh in article.findall('MedlineCitation/MeshHeadingList/')]),\n",
    "            'Descriptor_MajorTopic'   : SEP.join([getTextFromNode(mesh, 'DescriptorName', '', 1, 'MajorTopicYN') for mesh in article.findall('MedlineCitation/MeshHeadingList/')]),   \n",
    "            'Qualifier'               : SEP.join([getTextFromNode_quali(mesh, 'QualifierName') for mesh in article.findall('MedlineCitation/MeshHeadingList/')]),\n",
    "            'Qualifier_UI'            : SEP.join([getTextFromNode_quali_UI(mesh, 'QualifierName', '', 1, 'UI') for mesh in article.findall('MedlineCitation/MeshHeadingList/')]),\n",
    "            'Qualifier_MajorTopic'    : SEP.join([getTextFromNode_quali_YN(mesh, 'QualifierName', '', 1, 'MajorTopicYN') for mesh in article.findall('MedlineCitation/MeshHeadingList/')]),    \n",
    "        }\n",
    "        articleDics.append(OrderedDict(articleDic))\n",
    "    #データフレームにする\n",
    "    df = pd.DataFrame(articleDics)\n",
    "        \n",
    "    df[\"PubMedPubDate\"] = pd.to_datetime( df[\"PubMedPubDate_Y\"].astype('str')+'-'+df[\"PubMedPubDate_M\"].astype('str').str.zfill(2)+'-'+df[\"PubMedPubDate_D\"].astype('str').str.zfill(2))\n",
    "    del df[\"PubMedPubDate_Y\"]\n",
    "    del df[\"PubMedPubDate_M\"]\n",
    "    del df[\"PubMedPubDate_D\"]\n",
    "    \n",
    "    #区切り文字'|'で要素を分割し文字列リストにする        \n",
    "    df[\"Descriptor\"] = df[\"Descriptor\"].str.split('|')\n",
    "    df[\"Descriptor_UI\"] = df[\"Descriptor_UI\"].str.split('|')\n",
    "    df[\"Descriptor_MajorTopic\"] = df[\"Descriptor_MajorTopic\"].str.split('|')\n",
    "    df[\"Qualifier\"] = df[\"Qualifier\"].str.split('|')\n",
    "    df[\"Qualifier_UI\"] = df[\"Qualifier_UI\"].str.split('|')\n",
    "    df[\"Qualifier_MajorTopic\"] = df[\"Qualifier_MajorTopic\"].str.split('|')\n",
    "       \n",
    "\n",
    "    os.chdir(path_2)\n",
    "    one_descriptor_one_qualifier()\n",
    "    \n",
    "    os.chdir(path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['one_desc_one_qual_0001.csv']\n"
     ]
    }
   ],
   "source": [
    "#生成件数\n",
    "os.chdir(path_2)\n",
    "csv_list = sorted(glob.glob('*.csv'))\n",
    "print(len(csv_list), csv_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
